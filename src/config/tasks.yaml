orchestrate_task:
  description: >
    Analyze the user's request: "{user_input}"
    Determine the best specialist agent to handle it and delegate.
    Synthesize the result into a natural spoken response.
  expected_output: >
    A concise, natural-sounding response to the user's request
    suitable for text-to-speech output. Include any relevant data.
  agent: orchestrator

email_task:
  description: >
    Handle the user's email request: "{user_input}"
    Use Microsoft Graph tools to read, search, or draft emails.
    If the user wants to send an email, prepare a draft and
    request explicit approval before sending.
  expected_output: >
    A summary of emails found, or a draft email ready for approval,
    or confirmation of action taken. Keep responses concise.
  agent: email_agent

calendar_task:
  description: >
    Handle the user's calendar request: "{user_input}"
    Use Microsoft Graph calendar tools to list events, check
    availability, or prepare a new event. If creating an event,
    request explicit approval before creation.
  expected_output: >
    A summary of upcoming events, availability info, or a
    proposed event ready for approval. Keep responses concise.
  agent: calendar_agent

linear_task:
  description: >
    Handle the user's project management request: "{user_input}"
    Use Linear tools to list issues, search, create, or update.
    If creating or modifying issues, request explicit approval.
  expected_output: >
    A summary of issues found, or a proposed action ready for
    approval. Keep responses concise and actionable.
  agent: linear_agent

fireflies_task:
  description: >
    Handle the user's meeting query: "{user_input}"
    Use Fireflies tools to search transcripts, get summaries,
    and extract action items or key decisions.
  expected_output: >
    Meeting summaries, action items, key decisions, or
    relevant transcript excerpts. Keep responses concise.
  agent: fireflies_agent

vision_task:
  description: >
    Handle the user's vision request: "{user_input}"
    Capture a frame from the robot's camera and analyze it
    using the Vision Language Model. Answer the user's question
    about what is visible.
  expected_output: >
    A description of what the camera sees, answers to visual
    questions, or text read from the scene.
  agent: vision_agent

general_task:
  description: >
    Handle the user's general request: "{user_input}"
    Respond naturally and helpfully. Use your knowledge to
    answer questions, engage in conversation, or provide info.
  expected_output: >
    A natural, concise response suitable for spoken delivery
    via the robot's TTS system.
  agent: general_agent
